{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x185ae127e70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.FloatTensor([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])\n",
    "y_data = torch.FloatTensor([[0], [0], [0], [1], [1], [1]])\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(),lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0240],\n",
      "        [0.1476],\n",
      "        [0.2739],\n",
      "        [0.7967],\n",
      "        [0.9491],\n",
      "        [0.9836]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:   0/100 Cost: 0.133369 Acc 100.00%\n",
      "tensor([[0.0211],\n",
      "        [0.1427],\n",
      "        [0.2557],\n",
      "        [0.8051],\n",
      "        [0.9536],\n",
      "        [0.9851]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  10/100 Cost: 0.124978 Acc 100.00%\n",
      "tensor([[0.0185],\n",
      "        [0.1378],\n",
      "        [0.2401],\n",
      "        [0.8129],\n",
      "        [0.9577],\n",
      "        [0.9864]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  20/100 Cost: 0.117600 Acc 100.00%\n",
      "tensor([[0.0164],\n",
      "        [0.1330],\n",
      "        [0.2265],\n",
      "        [0.8200],\n",
      "        [0.9613],\n",
      "        [0.9877]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  30/100 Cost: 0.111060 Acc 100.00%\n",
      "tensor([[0.0146],\n",
      "        [0.1284],\n",
      "        [0.2143],\n",
      "        [0.8265],\n",
      "        [0.9644],\n",
      "        [0.9888]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  40/100 Cost: 0.105223 Acc 100.00%\n",
      "tensor([[0.0130],\n",
      "        [0.1241],\n",
      "        [0.2034],\n",
      "        [0.8326],\n",
      "        [0.9672],\n",
      "        [0.9897]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  50/100 Cost: 0.099983 Acc 100.00%\n",
      "tensor([[0.0117],\n",
      "        [0.1200],\n",
      "        [0.1935],\n",
      "        [0.8382],\n",
      "        [0.9696],\n",
      "        [0.9906]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  60/100 Cost: 0.095251 Acc 100.00%\n",
      "tensor([[0.0105],\n",
      "        [0.1162],\n",
      "        [0.1846],\n",
      "        [0.8434],\n",
      "        [0.9718],\n",
      "        [0.9913]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  70/100 Cost: 0.090958 Acc 100.00%\n",
      "tensor([[0.0095],\n",
      "        [0.1126],\n",
      "        [0.1765],\n",
      "        [0.8483],\n",
      "        [0.9738],\n",
      "        [0.9920]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  80/100 Cost: 0.087044 Acc 100.00%\n",
      "tensor([[0.0087],\n",
      "        [0.1092],\n",
      "        [0.1690],\n",
      "        [0.8529],\n",
      "        [0.9755],\n",
      "        [0.9926]], grad_fn=<SigmoidBackward>)\n",
      "Epoch:  90/100 Cost: 0.083461 Acc 100.00%\n",
      "tensor([[0.0079],\n",
      "        [0.1060],\n",
      "        [0.1622],\n",
      "        [0.8572],\n",
      "        [0.9771],\n",
      "        [0.9932]], grad_fn=<SigmoidBackward>)\n",
      "Epoch: 100/100 Cost: 0.080169 Acc 100.00%\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs+1):\n",
    "    \n",
    "    pred = model(x_data)\n",
    "    cost = F.binary_cross_entropy(pred, y_data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        p = pred>=torch.FloatTensor([0.5])\n",
    "        corr = p.float() == y_data\n",
    "        acc = corr.sum().item() / len(corr)\n",
    "        print('Epoch:{:4d}/{} Cost: {:.6f} Acc {:2.2f}%'.format(epoch,epochs,cost.item(),acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
