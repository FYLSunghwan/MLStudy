{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 Convolution Neural Network\n",
    "\n",
    "## Lab 10.1 Implementation of Simple CNN\n",
    "\n",
    "1x28x28 input\n",
    "\n",
    "Conv(5x5x5 Filter) -> 5x24x24\n",
    "\n",
    "pool(5x12x12)\n",
    "\n",
    "output(5x12x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "inputs = torch.Tensor(1,1,28,28)\n",
    "conv1 = nn.Conv2d(1,5,5)\n",
    "pool = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 12, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv1(inputs)\n",
    "out2 = pool(out)\n",
    "out.size()\n",
    "out2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10.2 MNIST CNN\n",
    "\n",
    "(Layer 1) Conv : in_c=1 out_c=32 k=3 st=1 pad=1\n",
    "\n",
    "(Layer 1) MaxPool : k=2 st=2\n",
    "\n",
    "\n",
    "(Layer 2) Conv : in_c=32 out_c=64 k=3 st=1 pad=1\n",
    "\n",
    "(Layer 2) MaxPool : k=2 st=2\n",
    "\n",
    "\n",
    "(View) batch_size x [7,7,64] to batch_size x [3136]\n",
    "\n",
    "(dense) input=3136 out=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import visdom\n",
    "\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    vis.line(X=num,\n",
    "            Y=loss_value,\n",
    "            win = loss_plot,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='dataset/MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='dataset/MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(3*3*128, 625, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(625,10,bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "value = torch.Tensor(1,1,28,28).to(device)\n",
    "print((model(value)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started\n",
      "Epoch:01 cost = 0.16126690804958344\n",
      "Epoch:02 cost = 0.04264891892671585\n",
      "Epoch:03 cost = 0.031033022329211235\n",
      "Epoch:04 cost = 0.02271990291774273\n",
      "Epoch:05 cost = 0.018666762858629227\n",
      "Epoch:06 cost = 0.015003982000052929\n",
      "Epoch:07 cost = 0.012411510571837425\n",
      "Epoch:08 cost = 0.012570415623486042\n",
      "Epoch:09 cost = 0.009091855958104134\n",
      "Epoch:10 cost = 0.008686444722115993\n",
      "Epoch:11 cost = 0.008385466411709785\n",
      "Epoch:12 cost = 0.006233751308172941\n",
      "Epoch:13 cost = 0.0066106137819588184\n",
      "Epoch:14 cost = 0.006250510923564434\n",
      "Epoch:15 cost = 0.006306073162704706\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "total_batch = len(data_loader)\n",
    "print('Learning Started')\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        \n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:{:02d} cost = {}'.format(epoch+1, avg_cost))\n",
    "    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy: ',accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10.3 Visdom Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom()  ### 가능한 Visdom을 켜놓고 진행을 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_376a9cc47427a8'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.text(\"Hello, world!\",env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_376a9d1811ba86'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(3,200,200)\n",
    "vis.image(a,env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_376a9d45f0bd92'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.images(torch.Tensor(3,3,28,28),env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of MNIST and CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:30, 16656457.90it/s]                                                                                   "
     ]
    }
   ],
   "source": [
    "MNIST = dsets.MNIST(root='dataset/MNIST_data/',\n",
    "                    train=True,\n",
    "                    transform=transforms.ToTensor(),\n",
    "                    download=True)\n",
    "\n",
    "cifar10 = dsets.CIFAR10(root='dataset/cifar10/',\n",
    "                      train=True,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_376a9e52b05646'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cifar10.__getitem__(0)\n",
    "print(data[0].shape)\n",
    "vis.images(data[0],env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_376a9e790b302a'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = MNIST.__getitem__(0)\n",
    "print(data[0].shape)\n",
    "vis.images(data[0],env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = MNIST,\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for num, value in enumerate(data_loader):\n",
    "    value = value[0]\n",
    "    print(value.shape)\n",
    "    vis.images(value, env=\"main\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = torch.randn(5)\n",
    "plt = vis.line(Y=Y_data, env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.Tensor([1,2,3,4,5])\n",
    "plt = vis.line(Y=Y_data, X=X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_376a9f394c64fe'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_append = torch.randn(1)\n",
    "X_append = torch.Tensor([6])\n",
    "\n",
    "vis.line(Y=Y_append, X=X_append, win=plt, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Line on Single Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "num = torch.Tensor(list(range(0,10)))\n",
    "print(num.shape)\n",
    "num = num.view(-1,1)\n",
    "print(num.shape)\n",
    "num = torch.cat((num,num),dim=1)\n",
    "print(num.shape)\n",
    "\n",
    "plt = vis.line(Y=torch.randn(10,2), X=num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=Y_data, X=X_data, opts = dict(title='Test', showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=Y_data, X=X_data, opts = dict(title='test', legend = ['1번'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=torch.randn(10,2), X=num, opts=dict(title='Test', legend=['1번', '2번']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Func for Update Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    \n",
    "    vis.line(X=num,\n",
    "            Y=loss_value,\n",
    "            win=loss_plot,\n",
    "            update='append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=torch.Tensor(1).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    loss = torch.randn(1) + i\n",
    "    loss_tracker(plt, loss, torch.Tensor([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.4 Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4.1 ImageFolder(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((64,128))\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='dataset/custom/mouth',transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 0\n",
      "1 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 0\n",
      "2 <PIL.Image.Image image mode=RGB size=128x64 at 0x206381482B0> 0\n",
      "3 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 0\n",
      "4 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 0\n",
      "5 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 0\n",
      "6 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 0\n",
      "7 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E10> 0\n",
      "8 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 0\n",
      "9 <PIL.Image.Image image mode=RGB size=128x64 at 0x206381482B0> 0\n",
      "10 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 0\n",
      "11 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 0\n",
      "12 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348F98> 0\n",
      "13 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 0\n",
      "14 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 0\n",
      "15 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 0\n",
      "16 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A240> 0\n",
      "17 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 0\n",
      "18 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A908> 0\n",
      "19 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 0\n",
      "20 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ADD8> 0\n",
      "21 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 0\n",
      "22 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A048> 0\n",
      "23 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 0\n",
      "24 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 0\n",
      "25 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 0\n",
      "26 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A908> 0\n",
      "27 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AE48> 0\n",
      "28 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 0\n",
      "29 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 0\n",
      "30 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 0\n",
      "31 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348F98> 0\n",
      "32 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A6A0> 0\n",
      "33 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A390> 0\n",
      "34 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A1D0> 0\n",
      "35 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A390> 0\n",
      "36 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496438> 0\n",
      "37 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 0\n",
      "38 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ACC0> 0\n",
      "39 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 0\n",
      "40 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 0\n",
      "41 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 0\n",
      "42 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 0\n",
      "43 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 0\n",
      "44 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A780> 0\n",
      "45 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A908> 0\n",
      "46 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 0\n",
      "47 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 0\n",
      "48 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 0\n",
      "49 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 0\n",
      "50 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ADD8> 1\n",
      "51 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 1\n",
      "52 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A320> 1\n",
      "53 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 1\n",
      "54 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 1\n",
      "55 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A400> 1\n",
      "56 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 1\n",
      "57 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 1\n",
      "58 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 1\n",
      "59 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 1\n",
      "60 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 1\n",
      "61 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AE48> 1\n",
      "62 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 1\n",
      "63 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063835F278> 1\n",
      "64 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 1\n",
      "65 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 1\n",
      "66 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A390> 1\n",
      "67 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 1\n",
      "68 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ACC0> 1\n",
      "69 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 1\n",
      "70 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ACC0> 1\n",
      "71 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 1\n",
      "72 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383608D0> 1\n",
      "73 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 1\n",
      "74 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 1\n",
      "75 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 1\n",
      "76 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 1\n",
      "77 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360CF8> 1\n",
      "78 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 1\n",
      "79 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 1\n",
      "80 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 1\n",
      "81 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 1\n",
      "82 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 1\n",
      "83 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A048> 1\n",
      "84 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360780> 1\n",
      "85 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A6A0> 1\n",
      "86 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 1\n",
      "87 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A6A0> 1\n",
      "88 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 1\n",
      "89 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E48> 1\n",
      "90 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ACC0> 1\n",
      "91 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 1\n",
      "92 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E10> 1\n",
      "93 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 1\n",
      "94 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496438> 1\n",
      "95 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 1\n",
      "96 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E48> 1\n",
      "97 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 1\n",
      "98 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 1\n",
      "99 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 1\n",
      "100 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 2\n",
      "101 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 2\n",
      "102 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 2\n",
      "103 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 2\n",
      "104 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A400> 2\n",
      "105 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E48> 2\n",
      "106 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A400> 2\n",
      "107 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 2\n",
      "108 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360C50> 2\n",
      "109 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 2\n",
      "110 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F28> 2\n",
      "111 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 2\n",
      "112 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 2\n",
      "113 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A908> 2\n",
      "114 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 2\n",
      "115 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 2\n",
      "116 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 2\n",
      "117 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348F98> 2\n",
      "118 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 2\n",
      "119 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348F98> 2\n",
      "120 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 2\n",
      "121 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360C50> 2\n",
      "123 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F28> 2\n",
      "124 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 2\n",
      "125 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AB70> 2\n",
      "126 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AC50> 2\n",
      "127 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AB70> 2\n",
      "128 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 2\n",
      "129 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A390> 2\n",
      "130 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ACC0> 2\n",
      "131 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 2\n",
      "132 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 2\n",
      "133 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 2\n",
      "134 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 2\n",
      "135 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 2\n",
      "136 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348F98> 2\n",
      "137 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 2\n",
      "138 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 2\n",
      "139 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 2\n",
      "140 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 2\n",
      "141 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E10> 2\n",
      "142 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 2\n",
      "143 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 2\n",
      "144 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 2\n",
      "145 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 2\n",
      "146 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 2\n",
      "147 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 2\n",
      "148 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360C50> 2\n",
      "149 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E10> 2\n",
      "150 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 3\n",
      "151 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 3\n",
      "152 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 3\n",
      "153 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 3\n",
      "154 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 3\n",
      "155 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 3\n",
      "156 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 3\n",
      "157 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 3\n",
      "158 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 3\n",
      "159 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 3\n",
      "160 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 3\n",
      "161 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 3\n",
      "162 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 3\n",
      "163 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360C50> 3\n",
      "164 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 3\n",
      "165 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AC50> 3\n",
      "166 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 3\n",
      "167 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 3\n",
      "168 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496978> 3\n",
      "169 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 3\n",
      "170 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 3\n",
      "171 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A1D0> 3\n",
      "172 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 3\n",
      "173 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A470> 3\n",
      "174 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F28> 3\n",
      "175 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 3\n",
      "176 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383608D0> 3\n",
      "177 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 3\n",
      "178 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360D68> 3\n",
      "179 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 3\n",
      "180 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360D68> 3\n",
      "181 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A320> 3\n",
      "182 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 3\n",
      "183 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348DA0> 3\n",
      "184 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496860> 3\n",
      "185 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 3\n",
      "186 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360CF8> 3\n",
      "187 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 3\n",
      "188 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 3\n",
      "189 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 3\n",
      "190 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496DD8> 3\n",
      "191 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AB70> 3\n",
      "192 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 3\n",
      "193 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A908> 3\n",
      "194 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A470> 3\n",
      "195 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063835F278> 3\n",
      "196 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496438> 3\n",
      "197 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496CC0> 3\n",
      "198 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063835F278> 3\n",
      "199 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 3\n",
      "200 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 4\n",
      "201 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 4\n",
      "202 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AE48> 4\n",
      "203 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 4\n",
      "204 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 4\n",
      "205 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496E80> 4\n",
      "206 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 4\n",
      "207 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 4\n",
      "208 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 4\n",
      "209 <PIL.Image.Image image mode=RGB size=128x64 at 0x206381482B0> 4\n",
      "210 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348F98> 4\n",
      "211 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 4\n",
      "212 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348D30> 4\n",
      "213 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348C50> 4\n",
      "214 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383608D0> 4\n",
      "215 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 4\n",
      "216 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 4\n",
      "217 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 4\n",
      "218 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360C50> 4\n",
      "219 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360D68> 4\n",
      "220 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496438> 4\n",
      "221 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360C50> 4\n",
      "222 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 4\n",
      "223 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ACC0> 4\n",
      "224 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 4\n",
      "225 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638347C18> 4\n",
      "226 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AB70> 4\n",
      "227 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 4\n",
      "228 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849A470> 4\n",
      "229 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 4\n",
      "230 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AC50> 4\n",
      "231 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AB70> 4\n",
      "232 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849AC50> 4\n",
      "233 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063835F278> 4\n",
      "234 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496438> 4\n",
      "235 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496EB8> 4\n",
      "236 <PIL.Image.Image image mode=RGB size=128x64 at 0x206381482B0> 4\n",
      "237 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638496F60> 4\n",
      "238 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 4\n",
      "239 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 4\n",
      "240 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 4\n",
      "241 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383609E8> 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605C0> 4\n",
      "243 <PIL.Image.Image image mode=RGB size=128x64 at 0x2063849ADD8> 4\n",
      "244 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 4\n",
      "245 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 4\n",
      "246 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383608D0> 4\n",
      "247 <PIL.Image.Image image mode=RGB size=128x64 at 0x206383605F8> 4\n",
      "248 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638348CC0> 4\n",
      "249 <PIL.Image.Image image mode=RGB size=128x64 at 0x20638360908> 4\n"
     ]
    }
   ],
   "source": [
    "for num, value in enumerate(train_data):\n",
    "    data, label = value\n",
    "    print(num, data, label)\n",
    "    \n",
    "    if(label == 0):\n",
    "        data.save('dataset/custom/newmouth/a/%d_%d.jpeg'%(num, label))\n",
    "    elif(label == 1):\n",
    "        data.save('dataset/custom/newmouth/e/%d_%d.jpeg'%(num, label))\n",
    "    elif(label == 2):\n",
    "        data.save('dataset/custom/newmouth/i/%d_%d.jpeg'%(num, label))\n",
    "    elif(label == 3):\n",
    "        data.save('dataset/custom/newmouth/o/%d_%d.jpeg'%(num, label))\n",
    "    else:\n",
    "        data.save('dataset/custom/newmouth/u/%d_%d.jpeg'%(num, label))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4.2 ImageFolder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import visdom\n",
    "\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    vis.line(X=num,\n",
    "            Y=loss_value,\n",
    "            win = loss_plot,\n",
    "            update = 'append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.00003\n",
    "training_epochs = 60\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='dataset/custom/newmouth',transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,6,kernel_size=5,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6,16,kernel_size=5,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(16*13*29,120,bias=True)\n",
    "        self.fc2 = nn.Linear(120, 5,bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)           \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "net = CNN().to(device)\n",
    "test_input = (torch.Tensor(3,3,64,128)).to(device)\n",
    "test_out = net(test_input)\n",
    "test_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 cost=1.5933713912963867\n",
      "Epoch:2 cost=1.5278387069702148\n",
      "Epoch:3 cost=1.445021152496338\n",
      "Epoch:4 cost=1.3446245193481445\n",
      "Epoch:5 cost=1.2613375186920166\n",
      "Epoch:6 cost=1.1571012735366821\n",
      "Epoch:7 cost=1.0983394384384155\n",
      "Epoch:8 cost=1.0276237726211548\n",
      "Epoch:9 cost=1.0073121786117554\n",
      "Epoch:10 cost=0.9745687246322632\n",
      "Epoch:11 cost=0.9312992095947266\n",
      "Epoch:12 cost=0.8917502164840698\n",
      "Epoch:13 cost=0.8829463720321655\n",
      "Epoch:14 cost=0.8444333076477051\n",
      "Epoch:15 cost=0.8650643229484558\n",
      "Epoch:16 cost=0.7936838865280151\n",
      "Epoch:17 cost=0.7835711240768433\n",
      "Epoch:18 cost=0.7950274348258972\n",
      "Epoch:19 cost=0.7296151518821716\n",
      "Epoch:20 cost=0.6602410078048706\n",
      "Epoch:21 cost=0.6744866967201233\n",
      "Epoch:22 cost=0.6110623478889465\n",
      "Epoch:23 cost=0.6063286662101746\n",
      "Epoch:24 cost=0.5788124203681946\n",
      "Epoch:25 cost=0.5394876599311829\n",
      "Epoch:26 cost=0.5299680829048157\n",
      "Epoch:27 cost=0.5481258630752563\n",
      "Epoch:28 cost=0.4954087734222412\n",
      "Epoch:29 cost=0.48393332958221436\n",
      "Epoch:30 cost=0.48442620038986206\n",
      "Epoch:31 cost=0.4823510944843292\n",
      "Epoch:32 cost=0.4706687331199646\n",
      "Epoch:33 cost=0.44217735528945923\n",
      "Epoch:34 cost=0.47101029753685\n",
      "Epoch:35 cost=0.4370462894439697\n",
      "Epoch:36 cost=0.45636075735092163\n",
      "Epoch:37 cost=0.41628512740135193\n",
      "Epoch:38 cost=0.4084555506706238\n",
      "Epoch:39 cost=0.421385794878006\n",
      "Epoch:40 cost=0.4097714424133301\n",
      "Epoch:41 cost=0.4175311326980591\n",
      "Epoch:42 cost=0.39084476232528687\n",
      "Epoch:43 cost=0.40277644991874695\n",
      "Epoch:44 cost=0.3814745545387268\n",
      "Epoch:45 cost=0.38715484738349915\n",
      "Epoch:46 cost=0.4033869802951813\n",
      "Epoch:47 cost=0.3797030448913574\n",
      "Epoch:48 cost=0.37548407912254333\n",
      "Epoch:49 cost=0.37917232513427734\n",
      "Epoch:50 cost=0.3851984441280365\n",
      "Epoch:51 cost=0.3848136067390442\n",
      "Epoch:52 cost=0.3649607300758362\n",
      "Epoch:53 cost=0.35839009284973145\n",
      "Epoch:54 cost=0.3760932683944702\n",
      "Epoch:55 cost=0.37971317768096924\n",
      "Epoch:56 cost=0.36208730936050415\n",
      "Epoch:57 cost=0.35468825697898865\n",
      "Epoch:58 cost=0.3573119640350342\n",
      "Epoch:59 cost=0.34865128993988037\n",
      "Epoch:60 cost=0.39023178815841675\n",
      "Learning Fin\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "    for num, data in enumerate(data_loader):\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = net(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss / total_batch\n",
    "    print('Epoch:{} cost={}'.format(epoch+1, avg_cost))\n",
    "print('Learning Fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./model/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net.load_state_dict(torch.load('./model/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root='dataset/custom/newmouth',transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796000063419342\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for num, data in enumerate(test_set):\n",
    "        imgs, label = data\n",
    "        imgs = imgs.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = net(imgs)\n",
    "        \n",
    "        correct_prediction = torch.argmax(pred, 1) == label\n",
    "        \n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:',accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((64,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image = Image.open('a.jpg')\n",
    "x = trans(image)\n",
    "x = x.view(1,3,64,128)\n",
    "x = x.to(device)\n",
    "pred = net(x)\n",
    "name = ['a','e','i','o','u']\n",
    "print(name[torch.argmax(pred, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
